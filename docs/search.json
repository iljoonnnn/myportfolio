[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "장일준",
    "section": "",
    "text": "안녕하세요??"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n2"
  },
  {
    "objectID": "hw1.html",
    "href": "hw1.html",
    "title": "hw1",
    "section": "",
    "text": "84p\n\nimport pandas as pd\nmydata = pd.DataFrame({'제품' : ['사과', '딸기', '수박'],\n          '가격' : [1800, 1500, 3000],\n          '판매량' : [24, 38, 13]})\nmydata\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\nprice_mean = sum(mydata['가격'])/len(mydata)\nprint('가격 평균=', price_mean)\nsales_mean = sum(mydata['판매량'])/len(mydata)\nprint('판매량 평균=', sales_mean)\n\n가격 평균= 2100.0\n판매량 평균= 25.0\n\n\n\n\n115p\n\nraw_data = pd.read_csv('data/mpg.csv')\nraw_data.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\nnew_data = raw_data.copy()\nnew_data = new_data.rename(columns = {'cty': 'city'})\nnew_data = new_data.rename(columns = {'hwy': 'hightway'})\nnew_data.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncity\nhightway\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\n\n130p\n\nraw_midwest = pd.read_csv('data/midwest.csv')\nraw_midwest.head()\nraw_midwest.tail()\nraw_midwest.shape\nraw_midwest.info()\nraw_midwest.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 437 entries, 0 to 436\nData columns (total 28 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   PID                   437 non-null    int64  \n 1   county                437 non-null    object \n 2   state                 437 non-null    object \n 3   area                  437 non-null    float64\n 4   poptotal              437 non-null    int64  \n 5   popdensity            437 non-null    float64\n 6   popwhite              437 non-null    int64  \n 7   popblack              437 non-null    int64  \n 8   popamerindian         437 non-null    int64  \n 9   popasian              437 non-null    int64  \n 10  popother              437 non-null    int64  \n 11  percwhite             437 non-null    float64\n 12  percblack             437 non-null    float64\n 13  percamerindan         437 non-null    float64\n 14  percasian             437 non-null    float64\n 15  percother             437 non-null    float64\n 16  popadults             437 non-null    int64  \n 17  perchsd               437 non-null    float64\n 18  percollege            437 non-null    float64\n 19  percprof              437 non-null    float64\n 20  poppovertyknown       437 non-null    int64  \n 21  percpovertyknown      437 non-null    float64\n 22  percbelowpoverty      437 non-null    float64\n 23  percchildbelowpovert  437 non-null    float64\n 24  percadultpoverty      437 non-null    float64\n 25  percelderlypoverty    437 non-null    float64\n 26  inmetro               437 non-null    int64  \n 27  category              437 non-null    object \ndtypes: float64(15), int64(10), object(3)\nmemory usage: 95.7+ KB\n\n\n\n\n\n\n\n\n\nPID\narea\npoptotal\npopdensity\npopwhite\npopblack\npopamerindian\npopasian\npopother\npercwhite\n...\nperchsd\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\n\n\n\n\ncount\n437.000000\n437.000000\n4.370000e+02\n437.000000\n4.370000e+02\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n...\n437.000000\n437.000000\n437.000000\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n\n\nmean\n1437.338673\n0.033169\n9.613030e+04\n3097.742985\n8.183992e+04\n1.102388e+04\n343.109840\n1310.464531\n1612.931350\n95.558441\n...\n73.965546\n18.272736\n4.447259\n9.364228e+04\n97.110267\n12.510505\n16.447464\n10.918798\n11.389043\n0.343249\n\n\nstd\n876.390266\n0.014679\n2.981705e+05\n7664.751786\n2.001966e+05\n7.895827e+04\n868.926751\n9518.394189\n18526.540699\n7.087358\n...\n5.843177\n6.261908\n2.408427\n2.932351e+05\n2.749863\n5.150155\n7.228634\n5.109166\n3.661259\n0.475338\n\n\nmin\n561.000000\n0.005000\n1.701000e+03\n85.050000\n4.160000e+02\n0.000000e+00\n4.000000\n0.000000\n0.000000\n10.694087\n...\n46.912261\n7.336108\n0.520291\n1.696000e+03\n80.902441\n2.180168\n1.918955\n1.938504\n3.547067\n0.000000\n\n\n25%\n670.000000\n0.024000\n1.884000e+04\n622.407407\n1.863000e+04\n2.900000e+01\n44.000000\n35.000000\n20.000000\n94.886032\n...\n71.325329\n14.113725\n2.997957\n1.836400e+04\n96.894572\n9.198715\n11.624088\n7.668009\n8.911763\n0.000000\n\n\n50%\n1221.000000\n0.030000\n3.532400e+04\n1156.208330\n3.447100e+04\n2.010000e+02\n94.000000\n102.000000\n66.000000\n98.032742\n...\n74.246891\n16.797562\n3.814239\n3.378800e+04\n98.169562\n11.822313\n15.270164\n10.007610\n10.869119\n0.000000\n\n\n75%\n2059.000000\n0.038000\n7.565100e+04\n2330.000000\n7.296800e+04\n1.291000e+03\n288.000000\n401.000000\n345.000000\n99.074935\n...\n77.195345\n20.549893\n4.949324\n7.284000e+04\n98.598636\n15.133226\n20.351878\n13.182182\n13.412162\n1.000000\n\n\nmax\n3052.000000\n0.110000\n5.105067e+06\n88018.396600\n3.204947e+06\n1.317147e+06\n10289.000000\n188565.000000\n384119.000000\n99.822821\n...\n88.898674\n48.078510\n20.791321\n5.023523e+06\n99.860384\n48.691099\n64.308477\n43.312464\n31.161972\n1.000000\n\n\n\n\n8 rows × 25 columns\n\n\n\n\nnew_midwest = raw_midwest.copy()\nnew_midwest = new_midwest.rename(columns = {'poptotal' : 'total'})\nnew_midwest = new_midwest.rename(columns = {'popasian' : 'asian'})\nnew_midwest.head()\n\n\n\n\n\n\n\n\nPID\ncounty\nstate\narea\ntotal\npopdensity\npopwhite\npopblack\npopamerindian\nasian\n...\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\ncategory\n\n\n\n\n0\n561\nADAMS\nIL\n0.052\n66090\n1270.961540\n63917\n1702\n98\n249\n...\n19.631392\n4.355859\n63628\n96.274777\n13.151443\n18.011717\n11.009776\n12.443812\n0\nAAR\n\n\n1\n562\nALEXANDER\nIL\n0.014\n10626\n759.000000\n7054\n3496\n19\n48\n...\n11.243308\n2.870315\n10529\n99.087145\n32.244278\n45.826514\n27.385647\n25.228976\n0\nLHR\n\n\n2\n563\nBOND\nIL\n0.022\n14991\n681.409091\n14477\n429\n35\n16\n...\n17.033819\n4.488572\n14235\n94.956974\n12.068844\n14.036061\n10.852090\n12.697410\n0\nAAR\n\n\n3\n564\nBOONE\nIL\n0.017\n30806\n1812.117650\n29344\n127\n46\n150\n...\n17.278954\n4.197800\n30337\n98.477569\n7.209019\n11.179536\n5.536013\n6.217047\n1\nALU\n\n\n4\n565\nBROWN\nIL\n0.018\n5836\n324.222222\n5264\n547\n14\n5\n...\n14.475999\n3.367680\n4815\n82.505140\n13.520249\n13.022889\n11.143211\n19.200000\n0\nAAR\n\n\n\n\n5 rows × 28 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.clf()\nnew_midwest['asian_total'] = new_midwest['asian'] / new_midwest['total'] * 100\nnew_midwest['asian_total'].plot.hist(rot=0)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nasian_total_mean = sum(new_midwest['asian_total']) / len(new_midwest)\nnew_midwest['grade'] = np.where(new_midwest['asian_total']&gt;asian_total_mean, 'large', 'small')\n\n\nmy_series = new_midwest['grade'].value_counts()\nplt.clf()\nmy_series.plot.bar(rot=0)\nplt.show()"
  },
  {
    "objectID": "hw2_240716.html",
    "href": "hw2_240716.html",
    "title": "hw2",
    "section": "",
    "text": "#라이브러리, 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('data/mpg.csv')\n\n\n\n\n#배기량이 4이하인 자동차의 고속도로 연비 평균\nmpg.query('displ &lt;= 4')['hwy'].mean()\n\nnp.float64(25.96319018404908)\n\n\n\n#배기량이 5이상상인 자동차의 고속도로 연비 평균\nmpg.query('displ &gt;= 5')['hwy'].mean()\n\nnp.float64(18.07894736842105)\n\n\n배기량이 4이하인 자동차의 고속도로 연비 평균이 더 높다.\n\n\n\n\n#아우디 자동차의 도시연비 평균\nmpg.query('manufacturer == \"audi\"')[\"cty\"].mean()\n\nnp.float64(17.61111111111111)\n\n\n\n#도요타 자동차의 도시연비 평균\nmpg.query('manufacturer == \"toyota\"')[\"cty\"].mean()\n\nnp.float64(18.529411764705884)\n\n\n도요타 자동차 연비 평균이 더 높다.\n\n\n\n\n#쉐보레, 포드, 혼다 자동차들의 고속도로 연비 평균\nmpg.query('manufacturer in [\"chevrolet\",\"fold\",\"honda\"]')[\"hwy\"].mean()\n\nnp.float64(25.321428571428573)"
  },
  {
    "objectID": "hw2_240716.html#q1",
    "href": "hw2_240716.html#q1",
    "title": "hw2",
    "section": "",
    "text": "#배기량이 4이하인 자동차의 고속도로 연비 평균\nmpg.query('displ &lt;= 4')['hwy'].mean()\n\nnp.float64(25.96319018404908)\n\n\n\n#배기량이 5이상상인 자동차의 고속도로 연비 평균\nmpg.query('displ &gt;= 5')['hwy'].mean()\n\nnp.float64(18.07894736842105)\n\n\n배기량이 4이하인 자동차의 고속도로 연비 평균이 더 높다."
  },
  {
    "objectID": "hw2_240716.html#q2",
    "href": "hw2_240716.html#q2",
    "title": "hw2",
    "section": "",
    "text": "#아우디 자동차의 도시연비 평균\nmpg.query('manufacturer == \"audi\"')[\"cty\"].mean()\n\nnp.float64(17.61111111111111)\n\n\n\n#도요타 자동차의 도시연비 평균\nmpg.query('manufacturer == \"toyota\"')[\"cty\"].mean()\n\nnp.float64(18.529411764705884)\n\n\n도요타 자동차 연비 평균이 더 높다."
  },
  {
    "objectID": "hw2_240716.html#q3",
    "href": "hw2_240716.html#q3",
    "title": "hw2",
    "section": "",
    "text": "#쉐보레, 포드, 혼다 자동차들의 고속도로 연비 평균\nmpg.query('manufacturer in [\"chevrolet\",\"fold\",\"honda\"]')[\"hwy\"].mean()\n\nnp.float64(25.321428571428573)"
  },
  {
    "objectID": "posts/hw1/index.html",
    "href": "posts/hw1/index.html",
    "title": "hw1",
    "section": "",
    "text": "84p\n\nimport pandas as pd\nmydata = pd.DataFrame({'제품' : ['사과', '딸기', '수박'],\n          '가격' : [1800, 1500, 3000],\n          '판매량' : [24, 38, 13]})\nmydata\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\nprice_mean = sum(mydata['가격'])/len(mydata)\nprint('가격 평균=', price_mean)\nsales_mean = sum(mydata['판매량'])/len(mydata)\nprint('판매량 평균=', sales_mean)\n\n가격 평균= 2100.0\n판매량 평균= 25.0\n\n\n\n\n115p\n\nraw_data = pd.read_csv('../../data/mpg.csv')\nraw_data.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\nnew_data = raw_data.copy()\nnew_data = new_data.rename(columns = {'cty': 'city'})\nnew_data = new_data.rename(columns = {'hwy': 'hightway'})\nnew_data.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncity\nhightway\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\n\n130p\n\nraw_midwest = pd.read_csv('../../data/midwest.csv')\nraw_midwest.head()\nraw_midwest.tail()\nraw_midwest.shape\nraw_midwest.info()\nraw_midwest.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 437 entries, 0 to 436\nData columns (total 28 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   PID                   437 non-null    int64  \n 1   county                437 non-null    object \n 2   state                 437 non-null    object \n 3   area                  437 non-null    float64\n 4   poptotal              437 non-null    int64  \n 5   popdensity            437 non-null    float64\n 6   popwhite              437 non-null    int64  \n 7   popblack              437 non-null    int64  \n 8   popamerindian         437 non-null    int64  \n 9   popasian              437 non-null    int64  \n 10  popother              437 non-null    int64  \n 11  percwhite             437 non-null    float64\n 12  percblack             437 non-null    float64\n 13  percamerindan         437 non-null    float64\n 14  percasian             437 non-null    float64\n 15  percother             437 non-null    float64\n 16  popadults             437 non-null    int64  \n 17  perchsd               437 non-null    float64\n 18  percollege            437 non-null    float64\n 19  percprof              437 non-null    float64\n 20  poppovertyknown       437 non-null    int64  \n 21  percpovertyknown      437 non-null    float64\n 22  percbelowpoverty      437 non-null    float64\n 23  percchildbelowpovert  437 non-null    float64\n 24  percadultpoverty      437 non-null    float64\n 25  percelderlypoverty    437 non-null    float64\n 26  inmetro               437 non-null    int64  \n 27  category              437 non-null    object \ndtypes: float64(15), int64(10), object(3)\nmemory usage: 95.7+ KB\n\n\n\n\n\n\n\n\n\nPID\narea\npoptotal\npopdensity\npopwhite\npopblack\npopamerindian\npopasian\npopother\npercwhite\n...\nperchsd\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\n\n\n\n\ncount\n437.000000\n437.000000\n4.370000e+02\n437.000000\n4.370000e+02\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n...\n437.000000\n437.000000\n437.000000\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n\n\nmean\n1437.338673\n0.033169\n9.613030e+04\n3097.742985\n8.183992e+04\n1.102388e+04\n343.109840\n1310.464531\n1612.931350\n95.558441\n...\n73.965546\n18.272736\n4.447259\n9.364228e+04\n97.110267\n12.510505\n16.447464\n10.918798\n11.389043\n0.343249\n\n\nstd\n876.390266\n0.014679\n2.981705e+05\n7664.751786\n2.001966e+05\n7.895827e+04\n868.926751\n9518.394189\n18526.540699\n7.087358\n...\n5.843177\n6.261908\n2.408427\n2.932351e+05\n2.749863\n5.150155\n7.228634\n5.109166\n3.661259\n0.475338\n\n\nmin\n561.000000\n0.005000\n1.701000e+03\n85.050000\n4.160000e+02\n0.000000e+00\n4.000000\n0.000000\n0.000000\n10.694087\n...\n46.912261\n7.336108\n0.520291\n1.696000e+03\n80.902441\n2.180168\n1.918955\n1.938504\n3.547067\n0.000000\n\n\n25%\n670.000000\n0.024000\n1.884000e+04\n622.407407\n1.863000e+04\n2.900000e+01\n44.000000\n35.000000\n20.000000\n94.886032\n...\n71.325329\n14.113725\n2.997957\n1.836400e+04\n96.894572\n9.198715\n11.624088\n7.668009\n8.911763\n0.000000\n\n\n50%\n1221.000000\n0.030000\n3.532400e+04\n1156.208330\n3.447100e+04\n2.010000e+02\n94.000000\n102.000000\n66.000000\n98.032742\n...\n74.246891\n16.797562\n3.814239\n3.378800e+04\n98.169562\n11.822313\n15.270164\n10.007610\n10.869119\n0.000000\n\n\n75%\n2059.000000\n0.038000\n7.565100e+04\n2330.000000\n7.296800e+04\n1.291000e+03\n288.000000\n401.000000\n345.000000\n99.074935\n...\n77.195345\n20.549893\n4.949324\n7.284000e+04\n98.598636\n15.133226\n20.351878\n13.182182\n13.412162\n1.000000\n\n\nmax\n3052.000000\n0.110000\n5.105067e+06\n88018.396600\n3.204947e+06\n1.317147e+06\n10289.000000\n188565.000000\n384119.000000\n99.822821\n...\n88.898674\n48.078510\n20.791321\n5.023523e+06\n99.860384\n48.691099\n64.308477\n43.312464\n31.161972\n1.000000\n\n\n\n\n8 rows × 25 columns\n\n\n\n\nnew_midwest = raw_midwest.copy()\nnew_midwest = new_midwest.rename(columns = {'poptotal' : 'total'})\nnew_midwest = new_midwest.rename(columns = {'popasian' : 'asian'})\nnew_midwest.head()\n\n\n\n\n\n\n\n\nPID\ncounty\nstate\narea\ntotal\npopdensity\npopwhite\npopblack\npopamerindian\nasian\n...\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\ncategory\n\n\n\n\n0\n561\nADAMS\nIL\n0.052\n66090\n1270.961540\n63917\n1702\n98\n249\n...\n19.631392\n4.355859\n63628\n96.274777\n13.151443\n18.011717\n11.009776\n12.443812\n0\nAAR\n\n\n1\n562\nALEXANDER\nIL\n0.014\n10626\n759.000000\n7054\n3496\n19\n48\n...\n11.243308\n2.870315\n10529\n99.087145\n32.244278\n45.826514\n27.385647\n25.228976\n0\nLHR\n\n\n2\n563\nBOND\nIL\n0.022\n14991\n681.409091\n14477\n429\n35\n16\n...\n17.033819\n4.488572\n14235\n94.956974\n12.068844\n14.036061\n10.852090\n12.697410\n0\nAAR\n\n\n3\n564\nBOONE\nIL\n0.017\n30806\n1812.117650\n29344\n127\n46\n150\n...\n17.278954\n4.197800\n30337\n98.477569\n7.209019\n11.179536\n5.536013\n6.217047\n1\nALU\n\n\n4\n565\nBROWN\nIL\n0.018\n5836\n324.222222\n5264\n547\n14\n5\n...\n14.475999\n3.367680\n4815\n82.505140\n13.520249\n13.022889\n11.143211\n19.200000\n0\nAAR\n\n\n\n\n5 rows × 28 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.clf()\nnew_midwest['asian_total'] = new_midwest['asian'] / new_midwest['total'] * 100\nnew_midwest['asian_total'].plot.hist(rot=0)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nasian_total_mean = sum(new_midwest['asian_total']) / len(new_midwest)\nnew_midwest['grade'] = np.where(new_midwest['asian_total']&gt;asian_total_mean, 'large', 'small')\n\n\nmy_series = new_midwest['grade'].value_counts()\nplt.clf()\nmy_series.plot.bar(rot=0)\nplt.show()"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "myblog",
    "section": "",
    "text": "LS Bigdata School Homework 8\n\n\n\nhomework\n\n\n\n\n\n\n\niljoon\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 7\n\n\n\nhomework\n\n\n\n\n\n\n\niljoon\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 6\n\n\n\nhomework\n\n\n\n\n\n\n\niljoon\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 5\n\n\n\nhomework\n\n\n\n\n\n\n\niljoon\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 4\n\n\n\nhomework\n\n\n\n\n\n\n\niljoon\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 3\n\n\n\nhomework\n\n\n\n\n\n\n\niljoon\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 2\n\n\n\nhomework\n\n\n\n\n\n\n\niljoon\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 1\n\n\n\nhomework\n\n\n\n\n\n\n\niljoon\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/hw2/index.html",
    "href": "posts/hw2/index.html",
    "title": "hw2",
    "section": "",
    "text": "#라이브러리, 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('../../data/mpg.csv')\n\n\n\n\n#배기량이 4이하인 자동차의 고속도로 연비 평균\nmpg.query('displ &lt;= 4')['hwy'].mean()\n\nnp.float64(25.96319018404908)\n\n\n\n#배기량이 5이상상인 자동차의 고속도로 연비 평균\nmpg.query('displ &gt;= 5')['hwy'].mean()\n\nnp.float64(18.07894736842105)\n\n\n배기량이 4이하인 자동차의 고속도로 연비 평균이 더 높다.\n\n\n\n\n#아우디 자동차의 도시연비 평균\nmpg.query('manufacturer == \"audi\"')[\"cty\"].mean()\n\nnp.float64(17.61111111111111)\n\n\n\n#도요타 자동차의 도시연비 평균\nmpg.query('manufacturer == \"toyota\"')[\"cty\"].mean()\n\nnp.float64(18.529411764705884)\n\n\n도요타 자동차 연비 평균이 더 높다.\n\n\n\n\n#쉐보레, 포드, 혼다 자동차들의 고속도로 연비 평균\nmpg.query('manufacturer in [\"chevrolet\",\"fold\",\"honda\"]')[\"hwy\"].mean()\n\nnp.float64(25.321428571428573)"
  },
  {
    "objectID": "posts/hw2/index.html#q1",
    "href": "posts/hw2/index.html#q1",
    "title": "hw2",
    "section": "",
    "text": "#배기량이 4이하인 자동차의 고속도로 연비 평균\nmpg.query('displ &lt;= 4')['hwy'].mean()\n\nnp.float64(25.96319018404908)\n\n\n\n#배기량이 5이상상인 자동차의 고속도로 연비 평균\nmpg.query('displ &gt;= 5')['hwy'].mean()\n\nnp.float64(18.07894736842105)\n\n\n배기량이 4이하인 자동차의 고속도로 연비 평균이 더 높다."
  },
  {
    "objectID": "posts/hw2/index.html#q2",
    "href": "posts/hw2/index.html#q2",
    "title": "hw2",
    "section": "",
    "text": "#아우디 자동차의 도시연비 평균\nmpg.query('manufacturer == \"audi\"')[\"cty\"].mean()\n\nnp.float64(17.61111111111111)\n\n\n\n#도요타 자동차의 도시연비 평균\nmpg.query('manufacturer == \"toyota\"')[\"cty\"].mean()\n\nnp.float64(18.529411764705884)\n\n\n도요타 자동차 연비 평균이 더 높다."
  },
  {
    "objectID": "posts/hw2/index.html#q3",
    "href": "posts/hw2/index.html#q3",
    "title": "hw2",
    "section": "",
    "text": "#쉐보레, 포드, 혼다 자동차들의 고속도로 연비 평균\nmpg.query('manufacturer in [\"chevrolet\",\"fold\",\"honda\"]')[\"hwy\"].mean()\n\nnp.float64(25.321428571428573)"
  },
  {
    "objectID": "posts/hw1/hw1.html",
    "href": "posts/hw1/hw1.html",
    "title": "LS Bigdata School Homework 1",
    "section": "",
    "text": "84p\n\nimport pandas as pd\nmydata = pd.DataFrame({'제품' : ['사과', '딸기', '수박'],\n          '가격' : [1800, 1500, 3000],\n          '판매량' : [24, 38, 13]})\nmydata\n\n\n\n\n\n\n\n\n제품\n가격\n판매량\n\n\n\n\n0\n사과\n1800\n24\n\n\n1\n딸기\n1500\n38\n\n\n2\n수박\n3000\n13\n\n\n\n\n\n\n\n\nprice_mean = sum(mydata['가격'])/len(mydata)\nprint('가격 평균=', price_mean)\nsales_mean = sum(mydata['판매량'])/len(mydata)\nprint('판매량 평균=', sales_mean)\n\n가격 평균= 2100.0\n판매량 평균= 25.0\n\n\n\n\n115p\n\nraw_data = pd.read_csv('../../data/mpg.csv')\nraw_data.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncty\nhwy\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\nnew_data = raw_data.copy()\nnew_data = new_data.rename(columns = {'cty': 'city'})\nnew_data = new_data.rename(columns = {'hwy': 'hightway'})\nnew_data.head()\n\n\n\n\n\n\n\n\nmanufacturer\nmodel\ndispl\nyear\ncyl\ntrans\ndrv\ncity\nhightway\nfl\ncategory\n\n\n\n\n0\naudi\na4\n1.8\n1999\n4\nauto(l5)\nf\n18\n29\np\ncompact\n\n\n1\naudi\na4\n1.8\n1999\n4\nmanual(m5)\nf\n21\n29\np\ncompact\n\n\n2\naudi\na4\n2.0\n2008\n4\nmanual(m6)\nf\n20\n31\np\ncompact\n\n\n3\naudi\na4\n2.0\n2008\n4\nauto(av)\nf\n21\n30\np\ncompact\n\n\n4\naudi\na4\n2.8\n1999\n6\nauto(l5)\nf\n16\n26\np\ncompact\n\n\n\n\n\n\n\n\n\n130p\n\nraw_midwest = pd.read_csv('../../data/midwest.csv')\nraw_midwest.head()\nraw_midwest.tail()\nraw_midwest.shape\nraw_midwest.info()\nraw_midwest.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 437 entries, 0 to 436\nData columns (total 28 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   PID                   437 non-null    int64  \n 1   county                437 non-null    object \n 2   state                 437 non-null    object \n 3   area                  437 non-null    float64\n 4   poptotal              437 non-null    int64  \n 5   popdensity            437 non-null    float64\n 6   popwhite              437 non-null    int64  \n 7   popblack              437 non-null    int64  \n 8   popamerindian         437 non-null    int64  \n 9   popasian              437 non-null    int64  \n 10  popother              437 non-null    int64  \n 11  percwhite             437 non-null    float64\n 12  percblack             437 non-null    float64\n 13  percamerindan         437 non-null    float64\n 14  percasian             437 non-null    float64\n 15  percother             437 non-null    float64\n 16  popadults             437 non-null    int64  \n 17  perchsd               437 non-null    float64\n 18  percollege            437 non-null    float64\n 19  percprof              437 non-null    float64\n 20  poppovertyknown       437 non-null    int64  \n 21  percpovertyknown      437 non-null    float64\n 22  percbelowpoverty      437 non-null    float64\n 23  percchildbelowpovert  437 non-null    float64\n 24  percadultpoverty      437 non-null    float64\n 25  percelderlypoverty    437 non-null    float64\n 26  inmetro               437 non-null    int64  \n 27  category              437 non-null    object \ndtypes: float64(15), int64(10), object(3)\nmemory usage: 95.7+ KB\n\n\n\n\n\n\n\n\n\nPID\narea\npoptotal\npopdensity\npopwhite\npopblack\npopamerindian\npopasian\npopother\npercwhite\n...\nperchsd\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\n\n\n\n\ncount\n437.000000\n437.000000\n4.370000e+02\n437.000000\n4.370000e+02\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n...\n437.000000\n437.000000\n437.000000\n4.370000e+02\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n437.000000\n\n\nmean\n1437.338673\n0.033169\n9.613030e+04\n3097.742985\n8.183992e+04\n1.102388e+04\n343.109840\n1310.464531\n1612.931350\n95.558441\n...\n73.965546\n18.272736\n4.447259\n9.364228e+04\n97.110267\n12.510505\n16.447464\n10.918798\n11.389043\n0.343249\n\n\nstd\n876.390266\n0.014679\n2.981705e+05\n7664.751786\n2.001966e+05\n7.895827e+04\n868.926751\n9518.394189\n18526.540699\n7.087358\n...\n5.843177\n6.261908\n2.408427\n2.932351e+05\n2.749863\n5.150155\n7.228634\n5.109166\n3.661259\n0.475338\n\n\nmin\n561.000000\n0.005000\n1.701000e+03\n85.050000\n4.160000e+02\n0.000000e+00\n4.000000\n0.000000\n0.000000\n10.694087\n...\n46.912261\n7.336108\n0.520291\n1.696000e+03\n80.902441\n2.180168\n1.918955\n1.938504\n3.547067\n0.000000\n\n\n25%\n670.000000\n0.024000\n1.884000e+04\n622.407407\n1.863000e+04\n2.900000e+01\n44.000000\n35.000000\n20.000000\n94.886032\n...\n71.325329\n14.113725\n2.997957\n1.836400e+04\n96.894572\n9.198715\n11.624088\n7.668009\n8.911763\n0.000000\n\n\n50%\n1221.000000\n0.030000\n3.532400e+04\n1156.208330\n3.447100e+04\n2.010000e+02\n94.000000\n102.000000\n66.000000\n98.032742\n...\n74.246891\n16.797562\n3.814239\n3.378800e+04\n98.169562\n11.822313\n15.270164\n10.007610\n10.869119\n0.000000\n\n\n75%\n2059.000000\n0.038000\n7.565100e+04\n2330.000000\n7.296800e+04\n1.291000e+03\n288.000000\n401.000000\n345.000000\n99.074935\n...\n77.195345\n20.549893\n4.949324\n7.284000e+04\n98.598636\n15.133226\n20.351878\n13.182182\n13.412162\n1.000000\n\n\nmax\n3052.000000\n0.110000\n5.105067e+06\n88018.396600\n3.204947e+06\n1.317147e+06\n10289.000000\n188565.000000\n384119.000000\n99.822821\n...\n88.898674\n48.078510\n20.791321\n5.023523e+06\n99.860384\n48.691099\n64.308477\n43.312464\n31.161972\n1.000000\n\n\n\n\n8 rows × 25 columns\n\n\n\n\nnew_midwest = raw_midwest.copy()\nnew_midwest = new_midwest.rename(columns = {'poptotal' : 'total'})\nnew_midwest = new_midwest.rename(columns = {'popasian' : 'asian'})\nnew_midwest.head()\n\n\n\n\n\n\n\n\nPID\ncounty\nstate\narea\ntotal\npopdensity\npopwhite\npopblack\npopamerindian\nasian\n...\npercollege\npercprof\npoppovertyknown\npercpovertyknown\npercbelowpoverty\npercchildbelowpovert\npercadultpoverty\npercelderlypoverty\ninmetro\ncategory\n\n\n\n\n0\n561\nADAMS\nIL\n0.052\n66090\n1270.961540\n63917\n1702\n98\n249\n...\n19.631392\n4.355859\n63628\n96.274777\n13.151443\n18.011717\n11.009776\n12.443812\n0\nAAR\n\n\n1\n562\nALEXANDER\nIL\n0.014\n10626\n759.000000\n7054\n3496\n19\n48\n...\n11.243308\n2.870315\n10529\n99.087145\n32.244278\n45.826514\n27.385647\n25.228976\n0\nLHR\n\n\n2\n563\nBOND\nIL\n0.022\n14991\n681.409091\n14477\n429\n35\n16\n...\n17.033819\n4.488572\n14235\n94.956974\n12.068844\n14.036061\n10.852090\n12.697410\n0\nAAR\n\n\n3\n564\nBOONE\nIL\n0.017\n30806\n1812.117650\n29344\n127\n46\n150\n...\n17.278954\n4.197800\n30337\n98.477569\n7.209019\n11.179536\n5.536013\n6.217047\n1\nALU\n\n\n4\n565\nBROWN\nIL\n0.018\n5836\n324.222222\n5264\n547\n14\n5\n...\n14.475999\n3.367680\n4815\n82.505140\n13.520249\n13.022889\n11.143211\n19.200000\n0\nAAR\n\n\n\n\n5 rows × 28 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.clf()\nnew_midwest['asian_total'] = new_midwest['asian'] / new_midwest['total'] * 100\nnew_midwest['asian_total'].plot.hist(rot=0)\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\nasian_total_mean = sum(new_midwest['asian_total']) / len(new_midwest)\nnew_midwest['grade'] = np.where(new_midwest['asian_total']&gt;asian_total_mean, 'large', 'small')\n\n\nmy_series = new_midwest['grade'].value_counts()\nplt.clf()\nmy_series.plot.bar(rot=0)\nplt.show()"
  },
  {
    "objectID": "posts/hw2/h2.html",
    "href": "posts/hw2/h2.html",
    "title": "LS Bigdata School Homework 2",
    "section": "",
    "text": "#라이브러리, 데이터 불러오기\nimport pandas as pd\nimport numpy as np\nmpg = pd.read_csv('../../data/mpg.csv')\n\n\n\n\n#배기량이 4이하인 자동차의 고속도로 연비 평균\nmpg.query('displ &lt;= 4')['hwy'].mean()\n\nnp.float64(25.96319018404908)\n\n\n\n#배기량이 5이상상인 자동차의 고속도로 연비 평균\nmpg.query('displ &gt;= 5')['hwy'].mean()\n\nnp.float64(18.07894736842105)\n\n\n배기량이 4이하인 자동차의 고속도로 연비 평균이 더 높다.\n\n\n\n\n#아우디 자동차의 도시연비 평균\nmpg.query('manufacturer == \"audi\"')[\"cty\"].mean()\n\nnp.float64(17.61111111111111)\n\n\n\n#도요타 자동차의 도시연비 평균\nmpg.query('manufacturer == \"toyota\"')[\"cty\"].mean()\n\nnp.float64(18.529411764705884)\n\n\n도요타 자동차 연비 평균이 더 높다.\n\n\n\n\n#쉐보레, 포드, 혼다 자동차들의 고속도로 연비 평균\nmpg.query('manufacturer in [\"chevrolet\",\"fold\",\"honda\"]')[\"hwy\"].mean()\n\nnp.float64(25.321428571428573)"
  },
  {
    "objectID": "posts/hw2/h2.html#q1",
    "href": "posts/hw2/h2.html#q1",
    "title": "LS Bigdata School Homework 2",
    "section": "",
    "text": "#배기량이 4이하인 자동차의 고속도로 연비 평균\nmpg.query('displ &lt;= 4')['hwy'].mean()\n\nnp.float64(25.96319018404908)\n\n\n\n#배기량이 5이상상인 자동차의 고속도로 연비 평균\nmpg.query('displ &gt;= 5')['hwy'].mean()\n\nnp.float64(18.07894736842105)\n\n\n배기량이 4이하인 자동차의 고속도로 연비 평균이 더 높다."
  },
  {
    "objectID": "posts/hw2/h2.html#q2",
    "href": "posts/hw2/h2.html#q2",
    "title": "LS Bigdata School Homework 2",
    "section": "",
    "text": "#아우디 자동차의 도시연비 평균\nmpg.query('manufacturer == \"audi\"')[\"cty\"].mean()\n\nnp.float64(17.61111111111111)\n\n\n\n#도요타 자동차의 도시연비 평균\nmpg.query('manufacturer == \"toyota\"')[\"cty\"].mean()\n\nnp.float64(18.529411764705884)\n\n\n도요타 자동차 연비 평균이 더 높다."
  },
  {
    "objectID": "posts/hw2/h2.html#q3",
    "href": "posts/hw2/h2.html#q3",
    "title": "LS Bigdata School Homework 2",
    "section": "",
    "text": "#쉐보레, 포드, 혼다 자동차들의 고속도로 연비 평균\nmpg.query('manufacturer in [\"chevrolet\",\"fold\",\"honda\"]')[\"hwy\"].mean()\n\nnp.float64(25.321428571428573)"
  },
  {
    "objectID": "Practice barplot.html",
    "href": "Practice barplot.html",
    "title": "Practice barplot",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nmpg = pd.read_csv(\"data/mpg.csv\")\n\n\n막대그래프\n\ndf_mpg = mpg.groupby(\"drv\", as_index = False) \\\n    .agg(mean_hwy = (\"hwy\", \"mean\"))\nplt.clf()\nsns.barplot(data = df_mpg.sort_values(\"mean_hwy\"),  #정렬 추가\n            x = \"drv\", y = \"mean_hwy\", hue = \"drv\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n빈도그래프\n\nplt.clf()\nsns.countplot(data = mpg, x = \"drv\")\nplt.show()"
  },
  {
    "objectID": "posts/Practice barplot/Practice barplot.html",
    "href": "posts/Practice barplot/Practice barplot.html",
    "title": "Practice plot",
    "section": "",
    "text": "데이터 및 패키지 불러오기\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nmpg = pd.read_csv(\"../../data/mpg.csv\")\n\n막대그래프\n\ndf_mpg = mpg.groupby(\"drv\", as_index = False) \\\n    .agg(mean_hwy = (\"hwy\", \"mean\"))\nplt.clf()\nsns.barplot(data = df_mpg.sort_values(\"mean_hwy\"),  #정렬 추가\n            x = \"drv\", y = \"mean_hwy\", hue = \"drv\")\nplt.show()\n\n\n\n\n\n\n\n\n빈도그래프\n\nplt.clf()\nsns.countplot(data = mpg, x = \"drv\")\nplt.show()\n\n\n\n\n\n\n\n\n*plotly를 사용한 산점도\n\npx.scatter(data_frame = mpg, x = 'cty', y = 'hwy', color = 'drv')\n#plt.show 명령어 하는거 아님.\n\n                                                \n\n\n다른 그래프 연습 1\n\npx.scatter(data_frame = mpg, x = 'year', y = 'hwy', color = 'manufacturer')\n\n                                                \n\n\n다른 그래프 연습 2\n\npx.scatter(data_frame = mpg, x = 'cty', y = 'displ', color = 'manufacturer')"
  },
  {
    "objectID": "posts/hw3/h3.html",
    "href": "posts/hw3/h3.html",
    "title": "LS Bigdata School Homework 3",
    "section": "",
    "text": "데이터 및 패키지 불러오기\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nmpg = pd.read_csv(\"../../data/mpg.csv\")\nmidwest = pd.read_csv(\"../../data/midwest.csv\")\n\n204p 혼자서 해보기\n\n#Q1\nplt.clf()\nsns.scatterplot(data = mpg, x = 'cty', y = 'hwy')\nplt.show()\n\n\n\n\n\n\n\n\n\n#Q2\nplt.clf()\nsns.scatterplot(data = midwest, x = 'poptotal', y = 'popasian')\\\n   .set(xlim = [0, 500000], ylim = [0, 10000])\nplt.show()\n\n\n\n\n\n\n\n\n211p 혼자서 해보기기\n\n#Q1\nmy_df = mpg.query('category == \"suv\"')\\\n           .groupby(\"manufacturer\")\\\n           .agg(mean_cty = ('cty', 'mean'))\\\n           .sort_values('mean_cty', ascending = False)\\\n           .head(5)\nplt.clf()\nsns.barplot(data = my_df, x = 'manufacturer', y = 'mean_cty')\nplt.show()\n\n\n\n\n\n\n\n\n\n#Q2\nplt.clf()\nmy_df2 = mpg.groupby(\"category\")\\\n            .agg(n = (\"category\", 'count'))\\\n            .sort_values('n', ascending = False)\nsns.barplot(data = my_df2, x = \"category\", y = 'n')\nplt.show()\n\n\n\n\n\n\n\n\n막대그래프\n\ndf_mpg = mpg.groupby(\"drv\", as_index = False) \\\n    .agg(mean_hwy = (\"hwy\", \"mean\"))\nplt.clf()\nsns.barplot(data = df_mpg.sort_values(\"mean_hwy\"),  #정렬 추가\n            x = \"drv\", y = \"mean_hwy\", hue = \"drv\")\nplt.show()\n\n\n\n\n\n\n\n\n빈도그래프\n\nplt.clf()\nsns.countplot(data = mpg, x = \"drv\")\nplt.show()\n\n\n\n\n\n\n\n\n*plotly를 사용한 산점도\n\npx.scatter(data_frame = mpg, x = 'cty', y = 'hwy', color = 'drv')\n#plt.show 명령어 하는거 아님.\n\n                                                \n\n\n다른 그래프 연습 1\n\npx.scatter(data_frame = mpg, x = 'year', y = 'hwy', color = 'manufacturer')\n\n                                                \n\n\n다른 그래프 연습 2\n\npx.scatter(data_frame = mpg, x = 'cty', y = 'displ', color = 'manufacturer')"
  },
  {
    "objectID": "posts/hw4/hw4.html",
    "href": "posts/hw4/hw4.html",
    "title": "LS Bigdata School Homework 4",
    "section": "",
    "text": "문제 1\n정규분포 pdf 값을 계산하는 자신만의 파이썬 함수를 정의하고, 정규분포 mu = 3, sigma = 2 의 pdf를 그릴 것. scipy.stats 함수 사용 안하고 하기.\n\n\n\n정규분포 함수 식\n\n\n\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\n\n\ndef nomal_distribution_function(x, mu, sigma):\n    result=(np.exp(1)**((((x-mu)/sigma)**2)/(-2)))/(sigma*np.sqrt(2*(math.pi)))\n    return result\n\n\nmyresult = nomal_distribution_function(0, 3, 2)\nprint(myresult)\n\n0.06475879783294587\n\n\n\nx = np.linspace(16, -10, 100)\ny = nomal_distribution_function(x, 3, 2)\nplt.scatter(x, y)\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n문제 2\n파이썬 scipy 패키지 사용해서 다음과 같은 확률을 구하시오. X ~ N(2, 3^2) 1) P(X &lt; 3) 2) P(2 &lt; X &lt; 5) 3) P(X &lt; 3 or X &gt; 7)\n\nfrom scipy.stats import bernoulli\nfrom scipy.stats import binom\nfrom scipy.stats import norm\n\n\n#1\nnorm.cdf(3, 2, 3)\n\nnp.float64(0.6305586598182363)\n\n\n\n#2\nnorm.cdf(5, 2, 3) - norm.cdf(2, 2, 3)\n\nnp.float64(0.3413447460685429)\n\n\n\n#3\nnorm.cdf(3, 2, 3) + (1 - norm.cdf(7, 2, 3))\n\nnp.float64(0.678349012091051)\n\n\n\n\n문제 3\nLS 빅데이터 스쿨 학생들의 중간고사 점수는 평균이 30이고, 분산이 4인 정규분포를 따른다. 상위 5%에 해당하는 학생의 점수는?\n\nnorm.ppf(0.95, 30, 2)\n\nnp.float64(33.28970725390295)"
  },
  {
    "objectID": "posts/hw5/hw5.html",
    "href": "posts/hw5/hw5.html",
    "title": "LS Bigdata School Homework 5",
    "section": "",
    "text": "분산 구할 때 n으로 나누기, n-1로 나누기 비교\n표본 분산 계산 시 왜 n-1로 나누는지 알아보도록 하겠습니다.\n균일분포 (3, 7)에서 20개의 표본을 뽑아서 분산을 2가지 방법으로 추정해보세요.\nn-1로 나눈 것을 s_2, n으로 나눈 것을 k_2로 정의하고, s_2의 분포와 k_2의 분포를 그려주세요! (10000개 사용) 각 분포 그래프에 모분산의 위치에 녹색 막대를 그려주세요. 결과를 살펴보고, 왜 n-1로 나눈 것을 분산을 추정하는 지표로 사용하는 것이 타당한지 써주세요!\n\n\n\n패키지 불러오기.\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom scipy.stats import uniform\n\n\n\n표본 분산 계산해보기\n\nnp.random.seed(20240729)\nx = uniform.rvs(loc = 3, scale = 4, size = 20)\nx_bar = np.mean(x)\nsum((x - x_bar)**2) / (len(x)-1)\n# 1.669\n\nnp.float64(1.6697498189003381)\n\n\n\n\n이론적인 분산 값\n\nmy_var = uniform.var(loc = 3, scale = 4)\n# 1.333\n\n\n\n몬테카를로 시뮬레이션을 이용해서 분산값 구하기.\n\nnp.random.seed(20240729)\nx = uniform.rvs(loc = 3, scale = 4, size = 20 * 10000)\nx.shape\nx = np.reshape(x, (-1, 20))\nx.shape\ns_2 = x.var(axis = 1, ddof = 1)  # n-1 으로 나누기.\nk_2 = x.var(axis = 1, ddof = 0) # n 으로 나누기.\n\n\n\ns_2 그래프 그리기\n\nplt.hist(s_2, bins = 40)\nplt.axvline(my_var, color = 'green', linestyle = 'dashed', linewidth = 2)\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\nk_2 그래프 그리기\n\nplt.hist(k_2, bins = 40)\nplt.axvline(my_var, color = 'green', linestyle = 'dashed', linewidth = 2)\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\ns_2 그래프가 이론적인 값에 더욱 가까운 것으로 확인 됨.\n\n\n이번엔 어떤 것이 이론적인 값에 가까웠는지 각각 경우마다 싸움을 붙여보겠다.\n\nresult = []\nfor i in range(10000):\n    if (s_2[i] - my_var)**2 &lt; (k_2[i] - my_var)**2:\n        result.append(\"s_2 win\")\n    elif (s_2[i] - my_var)**2 &gt; (k_2[i] - my_var)**2:\n        result.append(\"k_2 win\")\n# 10000개의 분산값을 각각 비교해서 이론적인 분산에 더 가까우면 그 방법을 1점 주는 반복문.\n\n\n\n싸움 결과 시각화.\n\nsns.countplot(data = result)\nplt.show()\nplt.clf()\n# n-1이 더 효과 있따!!!\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n결론\nn-1을 사용하는 것이 이론적인 값에 더욱 도달하는 것을 살펴봤다. 왜 분산값을 구할 때 n-1이 더 된 것인지지는 내일 설명을 들어야겠다.\n+코드 잘못된거 수정함_240730"
  },
  {
    "objectID": "posts/hw6/hw6.html",
    "href": "posts/hw6/hw6.html",
    "title": "LS Bigdata School Homework 6",
    "section": "",
    "text": "챕터 9-2 설문조사 그래프에서 각 성별 95% 신뢰구간 계산후 그리기\nnorm.ppf() 사용해서 그릴 것. 모분산은 표본 분산을 사용해서 추정\n위 아래 수직 막대기로 표시 (아래 그림 참조)\n\n\n\n숙제 그림\n\n\n\n패키지 불러오기\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n\n\n데이터 불러오기\n\n# 처음 데이터는 용량이 커서 어느정도 전처리 된 데이터를 불러왔다.\nwelfare = pd.read_csv(\"../../data/hw6_welfare.csv\")\n\n\n\n수업 시간 때 그렸던 그래프\n\nsex_income = welfare.dropna(subset = \"income\") \\\n       .groupby(\"sex\", as_index=False) \\\n       .agg(mean_income = (\"income\", \"mean\"))\nsex_income\n\nsns.barplot(data = sex_income, x = \"sex\", y = \"mean_income\", hue = \"sex\")\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n각 성별 95% 신뢰구간 계산\n\n\n\n여성-월급 테이블 / 남성-월급 테이블 뽑기\n\nfemale_income = welfare \\\n    .dropna(subset = \"income\") \\\n    .query('sex == \"female\"')[[\"sex\", \"income\"]]\n\nmale_income = welfare \\\n    .dropna(subset = \"income\") \\\n    .query('sex == \"male\"')[[\"sex\", \"income\"]]\n\n\n\n평균 구하기\n\nfemale_x_bar = female_income[\"income\"].mean() # 186.29309576837417\nmale_x_bar = male_income[\"income\"].mean() # 349.03757099169945\n\n\n\n표본분산 구하기\n\n# sum((female_income[\"income\"] - female_income_mean)**2) / (len(female_income)-1)\nfemale_s_2 = female_income[\"income\"].var() # 17439.157372096437\nmale_s_2 = male_income[\"income\"].var() # 47463.96187451692\n\n정규분포는 다음과 같이 표시한다. X_bar ~ N(mu, sigma^2 / n)\n모평균과 모 표준편차를 모르므로 다음과 같이 나타낸다 X_bar ~= N(x_bar, S^2 / n)\n\n\n따라서 정규분포에 들어갈 표준편차는 다음과 같이 구한다.\n\nfemale_sigma = np.sqrt(female_s_2) / np.sqrt(len(female_income)-1) # 2.78773393717896\nmale_sigma = np.sqrt(male_s_2) / np.sqrt(len(female_income)-1) # 4.599075794281872\n\n\n\n신뢰구간 95% 구하기\n\nfemale_025 = norm.ppf(0.025, loc = female_x_bar, scale = female_sigma)\n# 180.82923765302337\nfemale_975 = norm.ppf(0.975, loc = female_x_bar, scale = female_sigma)\n# 191.75695388372498\n\nmale_025 = norm.ppf(0.025, loc = male_x_bar, scale = male_sigma)\n# 340.023548072737\nmale_975 = norm.ppf(0.975, loc = male_x_bar, scale = male_sigma)\n# 358.0515939106619\n\n\n\n시각화 하기.\n\nsex_income = welfare.dropna(subset = \"income\") \\\n       .groupby(\"sex\", as_index=False) \\\n       .agg(mean_income = (\"income\", \"mean\"))\nsex_income\nsns.barplot(data = sex_income, x = \"sex\", y = \"mean_income\", hue = \"sex\")\n\nplt.vlines(x = 0, ymin = female_025, ymax = female_975, colors = \"green\")\nplt.vlines(x = 1, ymin = male_025, ymax = male_975, colors = \"green\")\nplt.show()\nplt.clf()\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n질문: 월급 평균의 95% 신뢰구간은 여기서부터 여기다~ 라고 할 수 있는건 알겠다. 그렇다면 이 말의 실질적인 의미는 “우리가 표본을 통해서 구한 신뢰구간 안에 모평균이 들어갈 확률이 95%이다.” 라는 것인가? 물어봐야겠다."
  },
  {
    "objectID": "posts/hw7/hw7.html",
    "href": "posts/hw7/hw7.html",
    "title": "LS Bigdata School Homework 7",
    "section": "",
    "text": "교제 57페이지 자동차 문제\n\nimport numpy as np\nfrom scipy.stats import t\nmyarray = np.array([15.078, 15.752, 15.549, 15.56, 16.098, 13.277, 15.462, 16.116, 15.214, 16.93, 14.118, 14.927, 15.382, 16.709, 16.804])\n\n\n\n2. 검정을 위한 가설을 명확하게 서술하시오.\n\n'''\nh0(귀무가설): 슬통 자동차는 에너지 소비 효율이 16.0 이상이다.\nhA(대립가설): 슬통 자동차는 에너지 소비 효율이 16.0 미만이다.\n'''\n\n'\\nh0(귀무가설): 슬통 자동차는 에너지 소비 효율이 16.0 이상이다.\\nhA(대립가설): 슬통 자동차는 에너지 소비 효율이 16.0 미만이다.\\n'\n\n\n\n\n3. 검정통계량 계산하시오.\n\n# t = {x_bar - mu0} / {S / root(n)}\nx_bar = myarray.mean() # 표본 평균 # 15.531\nmu_zero = 16.0 # 귀무가설에서 주장하는 평균 값\nmy_s = np.std(myarray, ddof=1) # n-1로 나눠진 분산의 제곱근 s\nmy_n = len(myarray) # n\n\nt_value = (x_bar - mu_zero) / (my_s / np.sqrt(my_n))\nt_value # -1.85\n\nnp.float64(-1.8500447456376756)\n\n\n\n\n4. p‑value을 구하세요. (유의확률)\n\np_value = t.cdf(x = t_value, df = my_n-1)\np_value #0.042\n\nnp.float64(0.042762417664207845)\n\n\n따라서 표본 평균 15.531이 틀릴 확률은 4.2% 이 확률은 유의수준 1%보다 높다. 15.531이 아닐 확률이 크다고 할 수 있다 따라서 16 이상이라고 본다. 귀무가설을 채택!\n\n\n6. 현대자동차의 신형 모델의 평균 복합 에너지 소비효율에 대하여 95% 신뢰구간을 구해보세요.\n\nx_bar + my_s / np.sqrt(my_n) # 15.784\nx_bar - my_s / np.sqrt(my_n) # 15.278\n# 15.278 ~ 15.784\n\nnp.float64(15.278622338169125)"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Recent posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nLS Bigdata School Homework 7\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 6\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 5\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 4\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 3\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 2\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 1\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "recent posts.html",
    "href": "recent posts.html",
    "title": "Recent posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nLS Bigdata School Homework 7\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 6\n\n\n\nJul 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 5\n\n\n\nJul 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 4\n\n\n\nJul 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 3\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 2\n\n\n\nJul 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLS Bigdata School Homework 1\n\n\n\nJul 15, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/hw8/hw8.html",
    "href": "posts/hw8/hw8.html",
    "title": "LS Bigdata School Homework 8",
    "section": "",
    "text": "로지스틱 회귀 예제\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\n\n'''\n종속변수: 백혈병 세포 관측 불가 여부 (REMISS), 1이면 관측 안됨을 의미\n\n독립변수:\n\n골수의 세포성 (CELL)\n골수편의 백혈구 비율 (SMEAR)\n골수의 백혈병 세포 침투 비율 (INFIL)\n골수 백혈병 세포의 라벨링 인덱스 (LI)\n말초혈액의 백혈병 세포 수 (BLAST)\n치료 시작 전 최고 체온 (TEMP)\n'''\n\n# 워킹 디렉토리 설정\nimport os\ncwd=os.getcwd()\nparent_dir = os.path.dirname(cwd)\nmain_dir = os.path.dirname(parent_dir)\nos.chdir(main_dir)\n\n\n\n문제 1. 데이터를 로드하고, 로지스틱 회귀모델을 적합하고, 회귀 표를 작성하세요.\n\n# 데이터 불러오기\ndf = pd.read_csv('./data/leukemia_remission.txt', sep='\\t')\ndf\n\n# 로지스틱 회귀모델 적합.\nmodel = sm.formula.logit(\"REMISS ~ CELL + SMEAR + INFIL + LI + BLAST + TEMP\", data=df).fit()\n\n# 회귀 표 출력\nprint(model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.399886\n         Iterations 10\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                 REMISS   No. Observations:                   27\nModel:                          Logit   Df Residuals:                       20\nMethod:                           MLE   Df Model:                            6\nDate:                Mon, 23 Sep 2024   Pseudo R-squ.:                  0.3718\nTime:                        21:11:22   Log-Likelihood:                -10.797\nconverged:                       True   LL-Null:                       -17.186\nCovariance Type:            nonrobust   LLR p-value:                   0.04670\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     64.2581     74.965      0.857      0.391     -82.670     211.187\nCELL          30.8301     52.135      0.591      0.554     -71.353     133.013\nSMEAR         24.6863     61.526      0.401      0.688     -95.903     145.275\nINFIL        -24.9745     65.281     -0.383      0.702    -152.923     102.974\nLI             4.3605      2.658      1.641      0.101      -0.849       9.570\nBLAST         -0.0115      2.266     -0.005      0.996      -4.453       4.430\nTEMP        -100.1734     77.753     -1.288      0.198    -252.567      52.220\n==============================================================================\n\nPossibly complete quasi-separation: A fraction 0.11 of observations can be\nperfectly predicted. This might indicate that there is complete\nquasi-separation. In this case some parameters will not be identified.\n\n\n\n\n문제 2. 해당 모델은 통계적으로 유의한가요? 그 이유를 검정통계량를 사용해서 설명하시오.\n\n'''\n유의수준 5%일 때 유의하다.\nLLR p-value: 0.04670 이기 때문에.\n'''\n\n'\\n유의수준 5%일 때 유의하다.\\nLLR p-value: 0.04670 이기 때문에.\\n'\n\n\n\n\n문제 3. 유의수준이 0.2를 기준으로 통계적으로 유의한 변수는 몇개이며, 어느 변수 인가요?\n\n'''\n유의수준 0.2 일 때 유의한 변수는 LI, TEMP\n'''\n\n'\\n유의수준 0.2 일 때 유의한 변수는 LI, TEMP\\n'\n\n\n\n\n문제 4. 다음 환자에 대한 오즈는 얼마인가요?\n\n# CELL (골수의 세포성): 65%\n# SMEAR (골수편의 백혈구 비율): 45%\n# INFIL (골수의 백혈병 세포 침투 비율): 55%\n# LI (골수 백혈병 세포의 라벨링 인덱스): 1.2\n# BLAST (말초혈액의 백혈병 세포 수): 1.1세포/μL\n# TEMP (치료 시작 전 최고 체온): 0.9\n\n## 로그 오즈 식\nlog_odds = 64.2581 + 30.8301 * 0.65 + 24.6863 * 0.45 -24.9745 * 0.55 + 4.3605 * 1.2 -0.0115 * 1.1 -100.1734 * 0.9\nlog_odds # -3.2655849999999873\n\n## 오즈 식\nmy_odds = np.exp(log_odds)\nmy_odds # 0.03817459641135519\n\nnp.float64(0.03817459641135519)\n\n\n\n\n문제 5. 위 환자의 혈액에서 백혈병 세포가 관측되지 않은 확률은 얼마인가요?\n\nmy_odds / (my_odds+1)\n# 0.03677088280074742\n# 3.6%\n\nnp.float64(0.03677088280074742)\n\n\n\n\n문제 6. TEMP 변수의 계수는 얼마이며, 해당 계수를 사용해서 TEMP 변수가 백혈병 치료에 대한 영향을 설명하시오.\n\n'''\nTEMP가 0.01 오르면 로그 오즈가 -1.001734 만큼 증가한다.(사실 떨어지는거.)\n이는 TEMP가 0.01 증가할 때마다 \"백혈병 세포가 관측 되지 않는 것\" 대한 오즈가 약 63.27% 떨어진다는 것이다.\n'''\nnp.exp(-1.001734) # 0.3672420909627784\n(0.3672420909627784 - 1) * 100\n\n-63.27579090372216\n\n\n\n\n문제 7. CELL 변수의 99% 오즈비에 대한 신뢰구간을 구하시오.\n\n# 모르겠다!!\n\n\n\n문제 8. 주어진 데이터에 대하여 로지스틱 회귀 모델의 예측 확률을 구한 후, 50% 이상인 경우 1로 처리하여, 혼동 행렬를 구하시오.\n\ndf = df.assign(odds = \n    np.exp(\n      64.2581 + 30.8301 * df['CELL'] + 24.6863 * df['SMEAR'] +\n      (-24.9745) * df['INFIL'] + 4.3605 * df['LI'] +\n      (-0.0115) * df['BLAST'] + (-100.1734) * df['TEMP']\n    ))\ndf = df.assign(remiss_probability =\n    df['odds'] / (df['odds'] + 1))\ndf = df.assign(classification =\n    np.where(df['remiss_probability'] &gt;= 0.5,\n             1, 0))\n\n\n\n문제 9. 해당 모델의 Accuracy는 얼마인가요?\n\nmymatrix = np.matrix([[\n    ((df['classification'] == 1) & (df['REMISS'] == 1)).sum(),\n    ((df['classification'] == 1) & (df['REMISS'] == 0)).sum()\n    ],\n    [\n    ((df['classification'] == 0) & (df['REMISS'] == 1)).sum(),\n    ((df['classification'] == 0) & (df['REMISS'] == 0)).sum()\n    ]])\n\n# 올바르게 예측한 샘플 개수\nmymatrix[0, 0] + mymatrix[1, 1] # 20\n\n# 전체 샘플 개수\nmymatrix[0, 0] + mymatrix[0, 1] + mymatrix[1, 0] + mymatrix[1, 1] # 27\n\n20/27 # Accuracy = 0.74\n\n0.7407407407407407\n\n\n\n\n문제 10. 해당 모델의 F1 Score를 구하세요.\n\nprecision = mymatrix[0, 0] / (mymatrix[0, 0] + mymatrix[0, 1]) # 0.625\nrecall = mymatrix[0, 0] / (mymatrix[0, 0] + mymatrix[1, 0]) # 0.555\n\n2 * (precision * recall) / (precision + recall) # 0.588\n\nnp.float64(0.5882352941176471)"
  }
]